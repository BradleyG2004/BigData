# ğŸ“Š Dashboard Grafana - Comparaison Cleaned vs Raw Data

## ğŸ¯ Vue d'ensemble

Le dashboard de comparaison permet de suivre en temps rÃ©el la diffÃ©rence entre :
- **DonnÃ©es brutes** (MongoDB collection `polymarket`)
- **DonnÃ©es nettoyÃ©es** (PostgreSQL table `polymarket_cleaned`)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MongoDB    â”‚  Collection 'polymarket' (raw)
â”‚   Atlas     â”‚  Collection 'cleaned'
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Stats collectÃ©es pÃ©riodiquement
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL (monitoring)    â”‚
â”‚  Table: mongodb_stats       â”‚  â—„â”€â”€â”€ Script: collect_mongo_stats.py
â”‚  - collection_name          â”‚
â”‚  - document_count           â”‚
â”‚  - metadata (JSONB)         â”‚
â”‚  - timestamp                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ RequÃªtes SQL
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Grafana Dashboard          â”‚
â”‚  Panels:                    â”‚
â”‚  âœ… Cleaned Data Count      â”‚
â”‚  ğŸ“Š Raw Data Count          â”‚
â”‚  ğŸ” Quality Comparison      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ˆ Panels du Dashboard

### 1. Raw Data Count (MongoDB)
- **Source**: Table `mongodb_stats`
- **RequÃªte**: 
  ```sql
  SELECT 
    COALESCE(MAX(document_count), 0) as "ğŸ“Š Raw Data (MongoDB)"
  FROM mongodb_stats 
  WHERE collection_name = 'polymarket'
    AND timestamp >= NOW() - INTERVAL '1 hour';
  ```
- **Affichage**: Compteur avec derniÃ¨re valeur connue (1 heure)

### 2. Cleaned Data Count (PostgreSQL)
- **Source**: Table `polymarket_cleaned`
- **RequÃªte**: 
  ```sql
  SELECT COUNT(*) as "âœ… Cleaned Data (PostgreSQL)" 
  FROM polymarket_cleaned;
  ```
- **Affichage**: Compteur temps rÃ©el

### 3. Data Quality Comparison
- **Source**: Les deux sources (UNION ALL)
- **Colonnes**:
  - Data Source
  - Total Records
  - Unique Categories
  - With Images/Icons/Series
  - Data Quality %

### 4-8. Autres Panels
- Distribution par catÃ©gories
- Statut des Ã©vÃ©nements
- Top 30 Ã©vÃ©nements
- Timeline d'insertion
- ComplÃ©tude par catÃ©gorie

## ğŸš€ Utilisation

### Ã‰tape 1: DÃ©marrer la collecte des stats

**Mode unique** (une seule collecte):
```powershell
python collect_mongo_stats.py
```

**Mode continu** (collecte toutes les 5 minutes):
```powershell
python collect_mongo_stats.py --continuous --interval 300
```

Options disponibles:
- `--continuous`: Active le mode continu
- `--interval SECONDS`: Intervalle entre collectes (dÃ©faut: 300s)

### Ã‰tape 2: VÃ©rifier l'insertion des donnÃ©es

```powershell
# Connexion PostgreSQL (port 5433)
docker exec -it postgres-polymarket psql -U polymarket -d polymarket
```

```sql
-- VÃ©rifier les derniÃ¨res stats collectÃ©es
SELECT 
    timestamp,
    collection_name,
    document_count,
    metadata->>'size_bytes' as size_bytes
FROM mongodb_stats
ORDER BY timestamp DESC
LIMIT 10;

-- Statistiques par collection
SELECT 
    collection_name,
    COUNT(*) as nb_entries,
    MAX(document_count) as max_documents,
    MIN(timestamp) as first_entry,
    MAX(timestamp) as last_entry
FROM mongodb_stats
GROUP BY collection_name;
```

### Ã‰tape 3: AccÃ©der au Dashboard

1. Ouvrir Grafana: http://localhost:3000
2. Login: `admin` / `admin`
3. Aller dans **Dashboards** â†’ **Polymarket - Cleaned vs Raw Data Comparison**
4. Refresh: Automatique toutes les 1 minute

## ğŸ”§ Configuration

### Variables d'environnement (.env)

```env
# MongoDB
MONGO_URI=mongodb+srv://user:password@cluster.mongodb.net/
MONGO_DB=polymarket

# PostgreSQL (monitoring)
POSTGRES_HOST=localhost
POSTGRES_PORT=5433
POSTGRES_DB=polymarket
POSTGRES_USER=polymarket
POSTGRES_PASSWORD=polymarket123
```

### Structure de la table mongodb_stats

```sql
CREATE TABLE mongodb_stats (
    id SERIAL PRIMARY KEY,
    timestamp TIMESTAMP NOT NULL DEFAULT NOW(),
    collection_name VARCHAR(100),
    document_count BIGINT,              -- Nombre de documents
    insert_count INTEGER,                -- Nombre d'insertions (optionnel)
    insert_duration_ms INTEGER,          -- DurÃ©e d'insertion (optionnel)
    metadata JSONB                       -- MÃ©tadonnÃ©es supplÃ©mentaires
);

-- Index pour les requÃªtes Grafana
CREATE INDEX IF NOT EXISTS idx_mongodb_stats_collection_time 
    ON mongodb_stats(collection_name, timestamp DESC);
```

### MÃ©tadonnÃ©es JSONB stockÃ©es

```json
{
  "size_bytes": 12345678,
  "avg_doc_size": 1024,
  "storage_size": 15000000,
  "total_indexes": 3,
  "index_sizes": {
    "_id_": 524288,
    "condition_id_1": 262144
  }
}
```

## ğŸ“Š Exemple d'utilisation avec Airflow

Ajoutez une tÃ¢che dans votre DAG pour collecter les stats:

```python
from airflow.operators.python import PythonOperator
import subprocess

def collect_mongodb_statistics():
    """Collecte les statistiques MongoDB pour Grafana"""
    result = subprocess.run(
        ['python', '/opt/airflow/collect_mongo_stats.py'],
        capture_output=True,
        text=True
    )
    if result.returncode != 0:
        raise Exception(f"Erreur collecte stats: {result.stderr}")
    print(result.stdout)

# Dans le DAG
collect_stats = PythonOperator(
    task_id='collect_mongodb_stats',
    python_callable=collect_mongodb_statistics
)

# Workflow
check_kafka >> fetch >> consume >> clean >> collect_stats >> load_postgres >> spark
```

## ğŸ› DÃ©pannage

### ProblÃ¨me: "No Data" dans le panel Raw Data

**Cause**: Aucune statistique collectÃ©e dans `mongodb_stats`

**Solution**:
```powershell
# 1. VÃ©rifier les connexions
python collect_mongo_stats.py

# 2. VÃ©rifier la table
docker exec -it postgres-polymarket psql -U polymarket -d polymarket -c "SELECT COUNT(*) FROM mongodb_stats;"

# 3. VÃ©rifier les logs
docker-compose logs postgres-polymarket
```

### ProblÃ¨me: Anciennes donnÃ©es affichÃ©es

**Cause**: RequÃªte Grafana filtre sur la derniÃ¨re heure

**Solution**: Modifier l'intervalle dans le dashboard JSON:
```sql
-- Changer de:
AND timestamp >= NOW() - INTERVAL '1 hour'

-- Ã€:
AND timestamp >= NOW() - INTERVAL '24 hours'
```

### ProblÃ¨me: Script Python plante

**Erreur commune**: `ModuleNotFoundError: No module named 'pymongo'`

**Solution**:
```powershell
# Installer les dÃ©pendances
pip install pymongo psycopg2-binary python-dotenv

# Ou via requirements.txt
pip install -r requirements.txt
```

## ğŸ“Œ Bonnes Pratiques

### 1. Collecte pÃ©riodique
- Utilisez un cron job ou Airflow pour collecter automatiquement
- Intervalle recommandÃ©: **5-10 minutes**
- Ã‰vitez les collectes trop frÃ©quentes (< 1 minute)

### 2. Nettoyage des donnÃ©es anciennes
```sql
-- Supprimer les stats de plus de 30 jours
DELETE FROM mongodb_stats 
WHERE timestamp < NOW() - INTERVAL '30 days';

-- Ou crÃ©er un script de maintenance
CREATE OR REPLACE FUNCTION cleanup_old_stats() 
RETURNS void AS $$
BEGIN
    DELETE FROM mongodb_stats 
    WHERE timestamp < NOW() - INTERVAL '30 days';
    
    RAISE NOTICE 'Stats anciennes supprimÃ©es';
END;
$$ LANGUAGE plpgsql;

-- Appel manuel ou via cron
SELECT cleanup_old_stats();
```

### 3. Monitoring de la collecte
```sql
-- Vue pour suivre la santÃ© de la collecte
CREATE OR REPLACE VIEW stats_collection_health AS
SELECT 
    collection_name,
    MAX(timestamp) as last_update,
    EXTRACT(EPOCH FROM (NOW() - MAX(timestamp))) / 60 as minutes_since_last_update,
    COUNT(*) as total_entries_today
FROM mongodb_stats
WHERE timestamp >= CURRENT_DATE
GROUP BY collection_name;

-- VÃ©rifier
SELECT * FROM stats_collection_health;
```

## ğŸ¯ RÃ©sultat Attendu

AprÃ¨s avoir lancÃ© `collect_mongo_stats.py` et attendu quelques minutes:

```
Dashboard Grafana affiche:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… Cleaned Data Count: 1,250       â”‚
â”‚ ğŸ“Š Raw Data Count: 1,500           â”‚
â”‚                                     â”‚
â”‚ Data Quality Comparison:            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ Source      â”‚ Records  â”‚ Qual % â”‚â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚ â”‚ Cleaned     â”‚ 1,250    â”‚ 95.2% â”‚â”‚
â”‚ â”‚ Raw (Mongo) â”‚ 1,500    â”‚ -     â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š Ressources

- [Dashboard JSON](./grafana/dashboards/polymarket-comparison-dashboard.json)
- [Script de collecte](./collect_mongo_stats.py)
- [Table monitoring](./postgres-init/01-init.sql)
- [Grafana Documentation](https://grafana.com/docs/)

---

**Auteur**: SystÃ¨me de monitoring Polymarket  
**Version**: 2.0  
**Date**: FÃ©vrier 2026
